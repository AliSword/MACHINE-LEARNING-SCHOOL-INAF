{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "## An example with Random Forests\n",
    "\n",
    "Adapted from https://www.kdnuggets.com/2018/06/step-forward-feature-selection-python.html by Umberto Michelucci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation Request:\n",
    "  This dataset is public available for research. The details are described in [Cortez et al., 2009]. \n",
    "  Please include this citation if you plan to use this database:\n",
    "\n",
    "  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "\n",
    "  Available at: [@Elsevier] http://dx.doi.org/10.1016/j.dss.2009.05.016\n",
    "                [Pre-press (pdf)] http://www3.dsi.uminho.pt/pcortez/winequality09.pdf\n",
    "                [bib] http://www3.dsi.uminho.pt/pcortez/dss09.bib\n",
    "\n",
    "1. Title: Wine Quality \n",
    "\n",
    "2. Sources\n",
    "   Created by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009\n",
    "   \n",
    "3. Past Usage:\n",
    "\n",
    "  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "\n",
    "  In the above reference, two datasets were created, using red and white wine samples.\n",
    "  The inputs include objective tests (e.g. PH values) and the output is based on sensory data\n",
    "  (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality \n",
    "  between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model\n",
    "  these datasets under a regression approach. The support vector machine model achieved the\n",
    "  best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T),\n",
    "  etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity\n",
    "  analysis procedure).\n",
    " \n",
    "4. Relevant Information:\n",
    "\n",
    "   The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine.\n",
    "   For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009].\n",
    "   Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables \n",
    "   are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n",
    "\n",
    "   These datasets can be viewed as classification or regression tasks.\n",
    "   The classes are ordered and not balanced (e.g. there are munch more normal wines than\n",
    "   excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent\n",
    "   or poor wines. Also, we are not sure if all input variables are relevant. So\n",
    "   it could be interesting to test feature selection methods. \n",
    "\n",
    "5. Number of Instances: red wine - 1599; white wine - 4898. \n",
    "\n",
    "6. Number of Attributes: 11 + output attribute\n",
    "  \n",
    "   Note: several of the attributes may be correlated, thus it makes sense to apply some sort of\n",
    "   feature selection.\n",
    "\n",
    "7. Attribute information:\n",
    "\n",
    "   For more information, read [Cortez et al., 2009].\n",
    "\n",
    "   Input variables (based on physicochemical tests):\n",
    "   1 - fixed acidity\n",
    "   2 - volatile acidity\n",
    "   3 - citric acid\n",
    "   4 - residual sugar\n",
    "   5 - chlorides\n",
    "   6 - free sulfur dioxide\n",
    "   7 - total sulfur dioxide\n",
    "   8 - density\n",
    "   9 - pH\n",
    "   10 - sulphates\n",
    "   11 - alcohol\n",
    "   Output variable (based on sensory data): \n",
    "   12 - quality (score between 0 and 10)\n",
    "\n",
    "8. Missing Attribute Values: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3673, 11) (3673,)\n",
      "Testing dataset shape: (1225, 11) (1225,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read data\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,:-1],\n",
    "    df.values[:,-1:],\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2024-01-18 23:02:10] Features: 1/5 -- score: 0.49277947691338114\n",
      "[2024-01-18 23:02:16] Features: 2/5 -- score: 0.5453342972066211\n",
      "[2024-01-18 23:02:22] Features: 3/5 -- score: 0.6082173904984337\n",
      "[2024-01-18 23:02:28] Features: 4/5 -- score: 0.6261862129047804\n",
      "[2024-01-18 23:02:33] Features: 5/5 -- score: 0.6376203451407811"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use those features to build a full model using our training and test sets. If we had a much larger set (i.e. many more instances as opposed to many more features), this would be especially beneficial as we could have used the feature selector above on a smaller subset of instances, determined our best performing subset of features, and then applied them to the full dataset for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected features: 0.559\n",
      "Testing accuracy on selected features: 0.512\n"
     ]
    }
   ],
   "source": [
    "# Build full model with selected features\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the actual accuracies; we're concerned here with the process, not the end result.\n",
    "\n",
    "But what if we were concerned with the end result, and wanted to know if our feature selection troubles had been worth it? Well, we could compare the resultant accuracies of the full model built using the selected features (immediately above) with the resultant accuracies of another full model using all of the features, just as we do below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on all features: 0.566\n",
      "Testing accuracy on all features: 0.509\n"
     ]
    }
   ],
   "source": [
    "# Build full model on ALL features, for comparison\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-jan24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
