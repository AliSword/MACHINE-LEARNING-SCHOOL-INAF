{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce8548f-1b46-444e-95af-870880da2371",
   "metadata": {},
   "source": [
    "# Linear Regression with scikit-learn\n",
    "\n",
    "Adapted from the original documentation.\n",
    "\n",
    "Author: Umberto Michelucci, TOELT LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b112be-e82b-436e-8e37-f9e2b7e9a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2aa43-56d3-4b0f-a508-4a6b7693f280",
   "metadata": {},
   "source": [
    "## Load the dataset (ingest)\n",
    "\n",
    "In this notebook we will use the diabetes dataset.\n",
    "\n",
    "The Diabetes dataset is a commonly used dataset for regression analysis. This dataset is publicly available and is frequently used for educational and benchmarking purposes in the field of data science and machine learning. Here is a detailed description:\n",
    "\n",
    "### Overview\n",
    "- The Diabetes dataset contains ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements taken from a group of diabetes patients.\n",
    "- It is a standard dataset used for understanding and practicing regression techniques in machine learning.\n",
    "- The dataset is relatively small, making it suitable for beginners and for testing algorithms quickly.\n",
    "\n",
    "### Composition\n",
    "- **Data Points**: It typically includes 442 patients' records.\n",
    "- **Features**: There are a total of ten baseline variables, some of which are physiological and others are laboratory measurements.\n",
    "- **Target Variable**: The quantitative measure of disease progression one year after baseline.\n",
    "- **No Missing Values**: The dataset is clean and does not contain missing values, which simplifies preprocessing steps.\n",
    "\n",
    "### Usage\n",
    "- **Regression Analysis**: It is primarily used for regression tasks where the goal is to predict the disease progression based on the baseline measurements.\n",
    "- **Benchmarking**: Due to its simplicity and well-understood characteristics, it's often used to benchmark performance of various regression algorithms.\n",
    "- **Educational Tool**: The dataset is an excellent tool for teaching machine learning concepts, especially regression analysis.\n",
    "\n",
    "### Format\n",
    "- The dataset is available in multiple formats and can be easily loaded using popular data science libraries like scikit-learn in Python.\n",
    "\n",
    "### Example of Loading in Python\n",
    "```python\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "```\n",
    "\n",
    "### Challenges\n",
    "- Despite its simplicity, the dataset presents challenges like feature selection and understanding the impact of each feature on disease progression, making it a good starting point for practicing these skills.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d4384a-5b36-4f00-a95e-120a81cef92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous line you can see how the dataset has 10 featuers (or columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20efd7de-40bc-4ab4-99ee-66ffce237147",
   "metadata": {},
   "source": [
    "## Select the features (data preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about ```np.newaxis```\n",
    "\n",
    "`np.newaxis` is a special index used in NumPy. It's used to increase the dimension of an existing array by one dimension, when used once. This is typically used to convert a one-dimensional array into a two-dimensional row or column matrix, or to increase the dimensionality of an array by one, at a specified axis.\n",
    "\n",
    "### Key Aspects of `np.newaxis`\n",
    "\n",
    "1. **Functionality**:\n",
    "   - `np.newaxis` is used within array indexing to create an additional dimension in a NumPy array. For example, if you have a 1D array of shape `(n,)` and you index it using `np.newaxis`, you can reshape it to either `(1, n)` or `(n, 1)`.\n",
    "\n",
    "2. **Common Usage Scenarios**:\n",
    "   - **Reshaping for Mathematical Operations**: Often in linear algebra or in operations with arrays, you need to explicitly convert a 1D array into a row or column vector. This is particularly common when dealing with vectors and matrices in machine learning algorithms.\n",
    "   - **Broadcasting**: In operations involving arrays of different dimensions, `np.newaxis` can be used to reshape arrays for broadcasting to make their dimensions compatible.\n",
    "\n",
    "3. **Examples**:\n",
    "   - Convert a 1D array to a column vector:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     a = np.array([1, 2, 3])\n",
    "     column_vector = a[:, np.newaxis]\n",
    "     ```\n",
    "     `column_vector` will have the shape `(3, 1)`.\n",
    "   - Convert a 1D array to a row vector:\n",
    "     ```python\n",
    "     row_vector = a[np.newaxis, :]\n",
    "     ```\n",
    "     `row_vector` will have the shape `(1, 3)`.\n",
    "\n",
    "4. **Difference from `reshape`**:\n",
    "   - While `reshape` can also be used to change the dimensions of an array, `np.newaxis` is a quick and easy way to increase dimensions, especially handy in complex expressions where readability is a concern.\n",
    "\n",
    "5. **Compatibility with Python's `None`**:\n",
    "   - `np.newaxis` is actually an alias for `None`. So, using `None` in place of `np.newaxis` will yield the same results. This can be particularly useful for concise code writing.\n",
    "\n",
    "### Example in Context\n",
    "\n",
    "Consider a scenario in machine learning where you have a 1D array of features and you need to transform it into a 2D array for matrix operations or compatibility with certain functions or methods that expect inputs of a certain shape. Using `np.newaxis` allows for this transformation in a very intuitive and readable way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9e65be-843c-4a50-93b0-7e8b5bdf8253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87625cc3-44bd-4fb9-a06b-82795a9623d4",
   "metadata": {},
   "source": [
    "## Hold-out approach (see Lecture on model validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d54a18-078e-4f33-b5ad-6ca56e8cd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b7a4fc-a265-4fd2-8e4d-cf82454d926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a82ee-6dcc-4e07-ac19-f567a918007a",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinearRegression()` is a function in the scikit-learn library, a popular Python toolkit for machine learning. This function implements linear regression, a fundamental algorithm for regression analysis. Here's a detailed description:\n",
    "\n",
    "### Overview of `LinearRegression()`\n",
    "1. **Purpose**: \n",
    "   - The `LinearRegression()` function is used to fit a linear model to a dataset. The goal of linear regression is to model the linear relationship between a dependent variable and one or more independent variables.\n",
    "\n",
    "2. **Functionality**: \n",
    "   - It estimates the coefficients of the linear equation, involving one or more independent variables that best predict the value of the dependent variable.\n",
    "\n",
    "### Key Features\n",
    "1. **Syntax**:\n",
    "   ```python\n",
    "   from sklearn.linear_model import LinearRegression\n",
    "   model = LinearRegression(*, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "   ```\n",
    "2. **Parameters**:\n",
    "   - `fit_intercept`: Boolean, decides whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations.\n",
    "   - `normalize`: This parameter is deprecated. It previously normalized the regressors (X) before regression by subtracting the mean and dividing by the l2-norm.\n",
    "   - `copy_X`: If True, X will be copied; else, it may be overwritten.\n",
    "   - `n_jobs`: The number of jobs to use for computation. `None` means 1, and `-1` means using all processors.\n",
    "\n",
    "3. **Methods**:\n",
    "   - `fit(X, y[, sample_weight])`: Fit the linear model to the data.\n",
    "   - `predict(X)`: Predict using the linear model.\n",
    "   - `score(X, y[, sample_weight])`: Return the coefficient of determination \\(R^2\\) of the prediction.\n",
    "\n",
    "4. **Attributes**:\n",
    "   - `coef_`: The coefficients of the linear model.\n",
    "   - `intercept_`: The intercept of the model (if `fit_intercept` is True).\n",
    "\n",
    "5. **Use Cases**:\n",
    "   - Suitable for both simple linear regression (one independent variable) and multiple linear regression (more than one independent variable).\n",
    "\n",
    "6. **Performance**:\n",
    "   - Efficient for datasets with a large number of features or instances.\n",
    "   - Performs well on both sparse and dense data.\n",
    "\n",
    "### Practical Example\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# Creating and fitting the model\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "# Predicting values\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Model coefficients\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2611ed23-fa0e-49f9-bbca-bfd268d8570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16023a8c-2a86-4705-a33e-659aa5fc7670",
   "metadata": {},
   "source": [
    "## Make Predictions and print the results\n",
    "\n",
    "The `predict()` method in scikit-learn is a commonly used function across various supervised learning algorithms. It is used to make predictions on the data after a model has been trained. Here's a detailed description:\n",
    "\n",
    "### Overview of `predict()`\n",
    "1. **Purpose**: \n",
    "   - The primary purpose of the `predict()` method is to apply a trained model to new, unseen data and produce predictions. In the context of supervised learning, these predictions correspond to the output variable (or target) that the model has learned to estimate.\n",
    "\n",
    "2. **Applicability**: \n",
    "   - It is used across a wide range of scikit-learn models, including regression models, classifiers, and more. \n",
    "\n",
    "### Key Features\n",
    "1. **Syntax**:\n",
    "   ```python\n",
    "   predictions = model.predict(X)\n",
    "   ```\n",
    "   - Here, `model` is a trained scikit-learn model, and `X` is the new data for which predictions are needed.\n",
    "\n",
    "2. **Parameters**:\n",
    "   - The primary parameter for `predict()` is the input data (`X`). This data should have the same number of features as the data used to train the model and should be formatted similarly (e.g., as a NumPy array or a Pandas DataFrame).\n",
    "\n",
    "3. **Output**:\n",
    "   - The output of `predict()` is an array of predicted values corresponding to the input data. In a classification context, these might be class labels; in regression, they are numerical predictions.\n",
    "\n",
    "4. **Pre-requisites**:\n",
    "   - The model must be trained using `.fit()` method before calling `predict()`. Attempting to use `predict()` on an untrained model will result in an error.\n",
    "\n",
    "5. **Use Cases**:\n",
    "   - Used in both regression (predicting continuous values) and classification (predicting class labels).\n",
    "   - Commonly used in the final step of a machine learning pipeline, after training and validation.\n",
    "\n",
    "### Practical Example\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generating synthetic regression data\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "# Training the model\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "# Making predictions\n",
    "predictions = model.predict(X)\n",
    "```\n",
    "\n",
    "### Considerations\n",
    "- The input data for `predict()` should be preprocessed in the same way as the training data (e.g., scaling, encoding).\n",
    "- For probabilistic models, such as some classifiers, `predict_proba()` can be used instead to get the probability of each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ```coef_``` parameter\n",
    "\n",
    "The `coef_` attribute in the `LinearRegression()` class from scikit-learn is a critical parameter that represents the coefficients of the linear regression equation for each feature. Here's a detailed description:\n",
    "\n",
    "### Overview of `coef_`\n",
    "1. **Purpose**:\n",
    "   - In linear regression, the model seeks to fit a linear equation to observed data. The `coef_` attribute represents the coefficients (often denoted as $\\beta$) of this equation. Each coefficient indicates the strength and direction of the relationship between a predictor (independent variable) and the target (dependent variable).\n",
    "\n",
    "2. **Context in Linear Regression**:\n",
    "   - A linear regression model attempts to predict a target variable as a weighted sum of input features. The general form of the equation is:\n",
    "     $ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n $\n",
    "     Here, $ y $ is the target, $ x_1, x_2, ..., x_n $ are input features, and $ \\beta_1, \\beta_2, ..., \\beta_n $ are the coefficients represented by `coef_`. $\\beta_0 $ is the intercept.\n",
    "\n",
    "3. **Interpretation**:\n",
    "   - The values in `coef_` indicate how much the target variable is expected to increase when the corresponding feature increases by one unit, holding all other features constant.\n",
    "   - Positive values indicate a positive correlation, while negative values indicate a negative correlation.\n",
    "\n",
    "4. **Usage**:\n",
    "   - After training a LinearRegression model, you can access `coef_` to understand the influence of each feature on the prediction. This is crucial for interpreting the model.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generating synthetic data\n",
    "X, y = make_regression(n_features=3, n_samples=100)\n",
    "\n",
    "# Training the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Coefficients\n",
    "print(model.coef_)\n",
    "```\n",
    "\n",
    "### Considerations\n",
    "- The `coef_` attribute is only available after the model has been fit.\n",
    "- The number of coefficients will match the number of input features. Each coefficient corresponds to a specific feature.\n",
    "- These coefficients are key to understanding the contribution and importance of each feature to the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f0437c-1478-47e3-82c8-1a31b57c3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Coefficient of determination: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a919d49-7e35-419b-bee2-23f5aef49a34",
   "metadata": {},
   "source": [
    "## Visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfd7847-ce31-41ff-86e2-3d9723c39d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Try to re-do linear regression but with all the features instead of just two and print out all the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A - Broadcasting in Python\n",
    "\n",
    "Broadcasting in Python, particularly with NumPy arrays, is a powerful concept that allows arithmetic operations to be performed on arrays of different shapes. This process simplifies and speeds up computations without the need for explicit replication of data in memory. Here’s a detailed description:\n",
    "\n",
    "### What is Broadcasting?\n",
    "1. **Concept**: Broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. It follows a set of rules to apply binary functions (like addition, multiplication) on arrays of different sizes.\n",
    "\n",
    "2. **Purpose**: The main goal is to make array arithmetic more convenient and efficient. It enables you to perform operations on arrays of different shapes without needing to match their sizes manually.\n",
    "\n",
    "### How Broadcasting Works\n",
    "Broadcasting in NumPy follows a strict set of rules:\n",
    "1. **Rule 1 - Check Dimensions**: Compare the shapes of the two arrays dimension-wise, starting from the trailing dimensions. Prepend 1 to the shape of the smaller array until both shapes have the same length.\n",
    "2. **Rule 2 - Compatibility Check**: Two dimensions are compatible when:\n",
    "   - They are equal, or\n",
    "   - One of them is 1.\n",
    "3. **Rule 3 - Stretching Dimensions**: If the dimensions are compatible, stretch the dimension with size 1 to match the other. This stretching does not create new data but acts as a view of the original data.\n",
    "4. **Rule 4 - Perform Operation**: After stretching dimensions, execute the operation element-wise on the resulting arrays.\n",
    "\n",
    "### Examples of Broadcasting\n",
    "1. **Adding a Scalar to an Array**:\n",
    "   ```python\n",
    "   import numpy as np\n",
    "   a = np.array([1, 2, 3])\n",
    "   b = 2\n",
    "   c = a + b  # b is broadcasted to array [2, 2, 2]\n",
    "   ```\n",
    "2. **Adding Arrays of Different Shapes**:\n",
    "   ```python\n",
    "   a = np.array([[1, 2, 3], [4, 5, 6]])  # Shape (2, 3)\n",
    "   b = np.array([1, 2, 3])              # Shape (3,)\n",
    "   c = a + b  # b is broadcasted to [[1, 2, 3], [1, 2, 3]]\n",
    "   ```\n",
    "\n",
    "### Applications\n",
    "- **Efficient Computations**: Broadcasting is used for efficient mathematical operations on arrays of different sizes, avoiding the need for loops or vectorized operations.\n",
    "- **Memory Optimization**: It minimizes memory usage as it doesn’t require replicating the data.\n",
    "- **Widely Used in Data Science and Machine Learning**: Operations like normalizing data, applying functions across arrays, etc., often use broadcasting.\n",
    "\n",
    "### Limitations\n",
    "- If two arrays are not compatible according to the broadcasting rules, a `ValueError` is raised.\n",
    "- Understanding the implicit behavior of broadcasting can sometimes be challenging, especially in complex operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
