{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Learning Project - Part I\n",
        "\n",
        "**NOTE THAT THIS EXAMPLE IS MORE ADVANCED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oZWBWuCPbPJS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The California Housing Dataset\n",
        "\n",
        "The California Housing dataset is a popular dataset used in machine learning for regression analysis. It was originally compiled for a 1990 census study and has since been widely used for educational and benchmarking purposes in the field of data science and machine learning. Here's a detailed description:\n",
        "\n",
        "### Overview of the California Housing Dataset\n",
        "1. **Content**:\n",
        "   - The dataset contains data related to the housing conditions in California districts, as gathered from the 1990 census.\n",
        "   - It is often used for predicting housing prices based on various demographic and geographic attributes.\n",
        "\n",
        "2. **Features**:\n",
        "   - The dataset includes several features, typically around 8 to 9, such as:\n",
        "     - Median Income in a block\n",
        "     - Median House Age in a block\n",
        "     - Average number of rooms per household\n",
        "     - Average number of bedrooms per household\n",
        "     - Population per block\n",
        "     - Average house occupancy\n",
        "     - Latitude and Longitude of the block\n",
        "   - These features are used to predict the median house value in the area.\n",
        "\n",
        "3. **Target Variable**:\n",
        "   - The main variable of interest, or the target variable, is the median housing price for California districts.\n",
        "\n",
        "4. **Usage**:\n",
        "   - This dataset is commonly used for regression tasks in machine learning, where the goal is to predict the median house value based on other metrics.\n",
        "   - It's a good dataset for beginners to practice regression techniques due to its simplicity and the clear relationships between variables.\n",
        "\n",
        "### Availability and Loading\n",
        "- The California Housing dataset is available in several machine learning libraries, including scikit-learn. In scikit-learn, it can be loaded using the `fetch_california_housing` function:\n",
        "\n",
        "  ```python\n",
        "  from sklearn.datasets import fetch_california_housing\n",
        "  housing = fetch_california_housing()\n",
        "  ```\n",
        "\n",
        "### Applications\n",
        "- **Educational Tool**: It's widely used for educational purposes to teach regression analysis.\n",
        "- **Real-World Scenario**: The dataset provides a real-world scenario where regression techniques can be applied, making it a practical choice for hands-on learning.\n",
        "- **Model Benchmarking**: It is often used to benchmark the performance of various regression models.\n",
        "\n",
        "### Considerations\n",
        "- **Data Preprocessing**: Depending on the version of the dataset, some preprocessing steps like feature scaling or normalization might be required to optimize the performance of certain machine learning models.\n",
        "- **Geographical Data**: The inclusion of latitude and longitude allows for interesting geographical analyses but might require specific handling or domain knowledge for meaningful insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bh2iZiJbdnEN"
      },
      "outputs": [],
      "source": [
        "# Load the California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "data = pd.DataFrame(california.data, columns=california.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E7ZGGBNBR8qa",
        "outputId": "a96b3fd0-50b7-4219-fd3f-990111f3dd9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>1.5603</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.045455</td>\n",
              "      <td>1.133333</td>\n",
              "      <td>845.0</td>\n",
              "      <td>2.560606</td>\n",
              "      <td>39.48</td>\n",
              "      <td>-121.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>2.5568</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.114035</td>\n",
              "      <td>1.315789</td>\n",
              "      <td>356.0</td>\n",
              "      <td>3.122807</td>\n",
              "      <td>39.49</td>\n",
              "      <td>-121.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>1.7000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.205543</td>\n",
              "      <td>1.120092</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2.325635</td>\n",
              "      <td>39.43</td>\n",
              "      <td>-121.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>1.8672</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.329513</td>\n",
              "      <td>1.171920</td>\n",
              "      <td>741.0</td>\n",
              "      <td>2.123209</td>\n",
              "      <td>39.43</td>\n",
              "      <td>-121.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>2.3886</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.254717</td>\n",
              "      <td>1.162264</td>\n",
              "      <td>1387.0</td>\n",
              "      <td>2.616981</td>\n",
              "      <td>39.37</td>\n",
              "      <td>-121.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
              "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
              "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
              "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
              "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
              "...       ...       ...       ...        ...         ...       ...       ...   \n",
              "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
              "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
              "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
              "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
              "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
              "\n",
              "       Longitude  \n",
              "0        -122.23  \n",
              "1        -122.22  \n",
              "2        -122.24  \n",
              "3        -122.25  \n",
              "4        -122.25  \n",
              "...          ...  \n",
              "20635    -121.09  \n",
              "20636    -121.21  \n",
              "20637    -121.22  \n",
              "20638    -121.32  \n",
              "20639    -121.24  \n",
              "\n",
              "[20640 rows x 8 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One-hot encoding and Binning data\n",
        "\n",
        "### Binning with ```pandas.cut()```\n",
        "\n",
        "`pd.cut()` is a function from the Pandas library in Python, used to segment and sort data values into bins or categories. This function is particularly useful for converting a continuous variable into a categorical variable by categorizing the data into discrete intervals (bins). Here's a detailed description:\n",
        "\n",
        "### Overview of `pd.cut()`\n",
        "1. **Purpose**:\n",
        "   - The primary purpose of `pd.cut()` is to divide the range of a continuous variable into intervals and assign these intervals to the corresponding data points.\n",
        "\n",
        "2. **Functionality**:\n",
        "   - It allows you to specify the number of bins to use or the specific bin edges.\n",
        "   - Each bin can be a different size.\n",
        "   - You can also label the bins with specific names.\n",
        "\n",
        "### Key Features and Parameters\n",
        "1. **Syntax**:\n",
        "   ```python\n",
        "   pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates='raise')\n",
        "   ```\n",
        "   - `x`: The input array to be binned. It must be a one-dimensional array.\n",
        "   - `bins`: Defines the bin edges. Can be an integer specifying the number of equal-width bins, or a sequence of bin edges.\n",
        "   - `right`: Indicates whether bins include the rightmost edge or not.\n",
        "   - `labels`: Specifies the labels for the returned bins.\n",
        "   - `retbins`: Whether to return the bins or not.\n",
        "   - `precision`: The precision at which to store and display the bin labels.\n",
        "   - `include_lowest`: Whether the first interval should be left-inclusive or not.\n",
        "   - `duplicates`: If bin edges are not unique, raise an error or drop non-unique bins.\n",
        "\n",
        "2. **Usage**:\n",
        "   - Useful for grouping continuous variables into categories for analysis.\n",
        "   - Often used in data preprocessing for machine learning, data visualization, and statistical analysis.\n",
        "\n",
        "### Example Usage\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = pd.Series([0.1, 0.6, 0.2, 0.9, 0.15, 0.5])\n",
        "\n",
        "# Using pd.cut to bin data\n",
        "bins = pd.cut(data, bins=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
        "print(bins)\n",
        "```\n",
        "\n",
        "### Considerations\n",
        "- **Choice of Bins**: The way you define the bins can significantly impact the analysis. Equal-width bins are simple but may not be appropriate for all data distributions.\n",
        "- **Handling Outliers**: Be mindful of how outliers are treated and which bin they fall into.\n",
        "- **Data Distribution**: Understanding the underlying distribution of the data is important to make meaningful binning decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iWRE8a4CnS6t"
      },
      "outputs": [],
      "source": [
        "# Feature engineering: One-hot encode median_income\n",
        "bins = [-np.inf, 1.5, 3, 4.5, 6, np.inf]\n",
        "labels = [1, 2, 3, 4, 5]\n",
        "data['median_income_binned'] = pd.cut(data['MedInc'], bins=bins, labels=labels)\n",
        "data = pd.get_dummies(data, columns=['median_income_binned'], prefix='median_income_bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KSTJnBPIdowp"
      },
      "outputs": [],
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(data, california.target, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Pipelines\n",
        "\n",
        "`Pipeline()` in scikit-learn is a utility that helps in sequentially applying a list of transforms and a final estimator. Essentially, it chains together multiple steps in a machine learning process—such as data preprocessing, feature extraction, and model fitting—into a single, unified workflow. Here's a detailed description:\n",
        "\n",
        "### Overview of `Pipeline()`\n",
        "1. **Purpose**:\n",
        "   - The primary purpose of a `Pipeline` is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "   - It ensures that the same sequence of steps is applied during both training and prediction.\n",
        "\n",
        "2. **Functionality**:\n",
        "   - Each step of a pipeline is a tuple containing the name of the step and an instance of a transformer or estimator.\n",
        "   - All steps except the last one must be transformers (i.e., they must have a `fit` and `transform` method). The last step can be a transformer or an estimator (i.e., it must have a `fit` method).\n",
        "\n",
        "### Key Features and Parameters\n",
        "1. **Syntax**:\n",
        "   ```python\n",
        "   from sklearn.pipeline import Pipeline\n",
        "   pipeline = Pipeline(steps=[('name1', transform1), ('name2', transform2), ..., ('nameN', estimator)])\n",
        "   ```\n",
        "   - `steps`: A list of (name, transform) tuples (implementing `fit`/`transform`) that are chained, in the order in which they are chained, with the last object an estimator.\n",
        "\n",
        "2. **Usage**:\n",
        "   - Commonly used to combine preprocessing steps (like scaling, dimensionality reduction) with a model like a classifier or regressor.\n",
        "   - Simplifies the code and reduces the risk of forgetting a preprocessing step in prediction.\n",
        "\n",
        "3. **Example Usage**:\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   from sklearn.decomposition import PCA\n",
        "   from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "   pipeline = Pipeline(steps=[\n",
        "       ('scaler', StandardScaler()),\n",
        "       ('pca', PCA(n_components=2)),\n",
        "       ('classifier', RandomForestClassifier())\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "4. **Benefits**:\n",
        "   - **Convenience and encapsulation**: Only call `fit` and `predict` once on your data to fit a whole sequence of estimators.\n",
        "   - **Joint parameter selection**: Grid search over parameters of all estimators in the pipeline at once.\n",
        "   - **Safety**: Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
        "\n",
        "5. **Grid Search Integration**:\n",
        "   - Pipelines can be used with grid search to simultaneously adjust parameters for all transformers and the estimator.\n",
        "\n",
        "### Considerations\n",
        "- **Debugging**: While convenient, pipelines can sometimes be harder to debug due to their encapsulated nature.\n",
        "- **Custom Transformers**: You can create custom transformers to include in the pipeline as long as they implement the `fit` and `transform` methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OCRUVJTedruy"
      },
      "outputs": [],
      "source": [
        "# Define the pipelines for each model\n",
        "linear_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('linear', LinearRegression())\n",
        "])\n",
        "\n",
        "lasso_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lasso', Lasso())\n",
        "])\n",
        "\n",
        "ridge_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('ridge', Ridge())\n",
        "])\n",
        "\n",
        "elasticnet_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('elasticnet', ElasticNet())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qLzokfOUdtfK"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters to search over for each model\n",
        "grid_linear_params = {\n",
        "    'linear__fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "grid_lasso_params = {\n",
        "    'lasso__alpha': [0.1, 1, 10],\n",
        "    'lasso__max_iter': [100, 1000, 10000]\n",
        "}\n",
        "\n",
        "grid_ridge_params = {\n",
        "    'ridge__alpha': [0.1, 1, 10],\n",
        "    'ridge__max_iter': [100, 1000, 10000]\n",
        "}\n",
        "\n",
        "grid_elasticnet_params = {\n",
        "    'elasticnet__alpha': [0.1, 1, 10],\n",
        "    'elasticnet__l1_ratio': [0.1, 0.5, 0.9],\n",
        "    'elasticnet__max_iter': [100, 1000, 10000]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Search with ```GridSearchCV()```\n",
        "\n",
        "`GridSearchCV()` is a function in scikit-learn, a popular Python library for machine learning. It's used for hyperparameter tuning, allowing you to find the best parameters for your machine learning model. Here's a detailed description:\n",
        "\n",
        "### Overview of `GridSearchCV()`\n",
        "1. **Purpose**:\n",
        "   - The primary purpose of `GridSearchCV` is to perform an exhaustive search over specified parameter values for an estimator.\n",
        "   - The goal is to find the combination of parameters that yields the best model performance, as measured by a specified evaluation metric.\n",
        "\n",
        "2. **Functionality**:\n",
        "   - It trains the model multiple times on a range of values for the hyperparameters and evaluates each combination using cross-validation.\n",
        "   - The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n",
        "\n",
        "### Key Features and Parameters\n",
        "1. **Syntax**:\n",
        "   ```python\n",
        "   from sklearn.model_selection import GridSearchCV\n",
        "   grid_search = GridSearchCV(estimator, param_grid, scoring=None, n_jobs=None, refit=True, cv=None, ...)\n",
        "   ```\n",
        "   - `estimator`: The base model for which to search the hyperparameters.\n",
        "   - `param_grid`: Dictionary with parameters names (`str`) as keys and lists of parameter settings to try as values.\n",
        "   - `scoring`: Strategy to evaluate the performance of the cross-validated model on the test set.\n",
        "   - `n_jobs`: Number of jobs to run in parallel (can speed up the grid search).\n",
        "   - `refit`: Refit an estimator using the best found parameters on the whole dataset.\n",
        "   - `cv`: Determines the cross-validation splitting strategy.\n",
        "\n",
        "2. **Usage**:\n",
        "   - Commonly used with models to tune hyperparameters like `C` and `gamma` in SVM, `max_depth` for Decision Trees, or `learning_rate` in neural networks.\n",
        "   - Useful in almost all kinds of machine learning problems to boost model performance.\n",
        "\n",
        "3. **Example Usage**:\n",
        "   ```python\n",
        "   from sklearn.model_selection import GridSearchCV\n",
        "   from sklearn.svm import SVC\n",
        "\n",
        "   param_grid = {'C': [0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1]}\n",
        "   grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "   grid_search.fit(X_train, y_train)\n",
        "   print(grid_search.best_params_)\n",
        "   ```\n",
        "\n",
        "4. **Benefits**:\n",
        "   - **Comprehensive Search**: It provides a thorough approach to finding the optimal parameters.\n",
        "   - **Improved Model Accuracy**: Helps in improving the model's performance by fine-tuning the parameters.\n",
        "   - **Automation**: Automates the process of systematic parameter search and evaluation.\n",
        "\n",
        "### Considerations\n",
        "- **Computational Cost**: Can be computationally expensive, especially for large datasets and complex models.\n",
        "- **Overfitting**: There's a risk of overfitting on the training set since it evaluates many different models.\n",
        "- **Choice of Range and Scoring**: The ranges in `param_grid` and the choice of `scoring` metric significantly influence the effectiveness of the grid search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "vN0sg55AdvG_",
        "outputId": "ed9ac957-d3e8-4167-e734-4bc2932766ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;elasticnet&#x27;, ElasticNet())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;elasticnet__alpha&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;elasticnet__l1_ratio&#x27;: [0.1, 0.5, 0.9],\n",
              "                         &#x27;elasticnet__max_iter&#x27;: [100, 1000, 10000]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;elasticnet&#x27;, ElasticNet())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;elasticnet__alpha&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;elasticnet__l1_ratio&#x27;: [0.1, 0.5, 0.9],\n",
              "                         &#x27;elasticnet__max_iter&#x27;: [100, 1000, 10000]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;elasticnet&#x27;, ElasticNet())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('elasticnet', ElasticNet())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'elasticnet__alpha': [0.1, 1, 10],\n",
              "                         'elasticnet__l1_ratio': [0.1, 0.5, 0.9],\n",
              "                         'elasticnet__max_iter': [100, 1000, 10000]})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform hyperparameter tuning with GridSearchCV\n",
        "grid_search_linear = GridSearchCV(linear_pipeline, grid_linear_params, cv=5, n_jobs=-1)\n",
        "grid_search_lasso = GridSearchCV(lasso_pipeline, grid_lasso_params, cv=5, n_jobs=-1)\n",
        "grid_search_ridge = GridSearchCV(ridge_pipeline, grid_ridge_params, cv=5, n_jobs=-1)\n",
        "grid_search_elasticnet = GridSearchCV(elasticnet_pipeline, grid_elasticnet_params, cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search_linear.fit(X_trainval, y_trainval)\n",
        "grid_search_lasso.fit(X_trainval, y_trainval)\n",
        "grid_search_ridge.fit(X_trainval, y_trainval)\n",
        "grid_search_elasticnet.fit(X_trainval, y_trainval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KfiUk3IIq6al"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters to search over for each model\n",
        "rand_lasso_params = {\n",
        "    'lasso__alpha': np.arange(0, 10, 0.01),\n",
        "}\n",
        "\n",
        "rand_ridge_params = {\n",
        "    'ridge__alpha': np.arange(0, 10, 0.01),\n",
        "    'ridge__max_iter': [10, 100, 1000, 10000]\n",
        "}\n",
        "\n",
        "rand_elasticnet_params = {\n",
        "    'elasticnet__alpha': np.arange(0, 10, 0.01),\n",
        "    'elasticnet__l1_ratio': np.arange(0, 1, 0.01),\n",
        "    'elasticnet__max_iter': [10, 100, 1000, 10000]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Search with ```RandomizedSearchCV()```\n",
        "\n",
        "`RandomizedSearchCV` is a function in scikit-learn, a popular Python library for machine learning, used for hyperparameter tuning. Unlike `GridSearchCV` which exhaustively tries all possible parameter combinations, `RandomizedSearchCV` samples a fixed number of parameter settings from specified distributions. Here's a detailed description:\n",
        "\n",
        "### Overview of `RandomizedSearchCV`\n",
        "1. **Purpose**:\n",
        "   - The primary purpose of `RandomizedSearchCV` is to find the best parameters for a particular model, but instead of trying out all possible combinations, it randomly samples a given number of parameter combinations from the specified distributions.\n",
        "\n",
        "2. **Functionality**:\n",
        "   - This approach can be more efficient than `GridSearchCV`, especially when dealing with a large hyperparameter space or when each evaluation is very expensive.\n",
        "\n",
        "### Key Features and Parameters\n",
        "1. **Syntax**:\n",
        "   ```python\n",
        "   from sklearn.model_selection import RandomizedSearchCV\n",
        "   randomized_search = RandomizedSearchCV(estimator, param_distributions, n_iter=100, scoring=None, n_jobs=None, refit=True, cv=None, ...)\n",
        "   ```\n",
        "   - `estimator`: The base model to tune.\n",
        "   - `param_distributions`: Dictionary with parameters names (`str`) as keys and distributions or lists of parameters to try. Distributions must provide a `rvs` method for sampling (such as those from scipy.stats.distributions).\n",
        "   - `n_iter`: Number of parameter settings that are sampled. `n_iter` trades off runtime vs quality of the solution.\n",
        "   - `scoring`: Strategy to evaluate the performance of the cross-validated model on the test set.\n",
        "   - `n_jobs`: Number of jobs to run in parallel.\n",
        "   - `refit`: Refit an estimator using the best found parameters on the whole dataset.\n",
        "   - `cv`: Determines the cross-validation splitting strategy.\n",
        "\n",
        "2. **Usage**:\n",
        "   - Useful in scenarios where the parameter space is large, and it's computationally infeasible to try all combinations.\n",
        "   - Often used to optimize the hyperparameters of machine learning models to enhance their performance.\n",
        "\n",
        "3. **Example Usage**:\n",
        "   ```python\n",
        "   from sklearn.ensemble import RandomForestClassifier\n",
        "   from sklearn.model_selection import RandomizedSearchCV\n",
        "   from scipy.stats import randint\n",
        "\n",
        "   param_distributions = {'n_estimators': randint(100, 200), 'max_depth': [None, 10, 20, 30]}\n",
        "   randomized_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions, n_iter=100, cv=5)\n",
        "   randomized_search.fit(X_train, y_train)\n",
        "   print(randomized_search.best_params_)\n",
        "   ```\n",
        "\n",
        "4. **Benefits**:\n",
        "   - **Efficiency**: More efficient than `GridSearchCV` especially for large hyperparameter spaces.\n",
        "   - **Exploration**: Can explore a broader range of values and distributions for the hyperparameters.\n",
        "\n",
        "### Considerations\n",
        "- **Randomness**: The results can depend on the random seed due to the random nature of the parameter sampling.\n",
        "- **Coverage**: It might not cover the entire parameter space as thoroughly as `GridSearchCV`.\n",
        "- **Balance**: Requires balancing between `n_iter` (number of iterations) and the computational budget.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "VOHiOJBapS4I",
        "outputId": "d6111220-f191-4036-9871-444f75c0c97d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                             (&#x27;elasticnet&#x27;, ElasticNet())]),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={&#x27;elasticnet__alpha&#x27;: array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
              "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
              "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37...\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
              "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
              "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
              "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
              "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
              "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
              "       0.99]),\n",
              "                                        &#x27;elasticnet__max_iter&#x27;: [10, 100, 1000,\n",
              "                                                                 10000]},\n",
              "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                             (&#x27;elasticnet&#x27;, ElasticNet())]),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={&#x27;elasticnet__alpha&#x27;: array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
              "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
              "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37...\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
              "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
              "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
              "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
              "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
              "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
              "       0.99]),\n",
              "                                        &#x27;elasticnet__max_iter&#x27;: [10, 100, 1000,\n",
              "                                                                 10000]},\n",
              "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;elasticnet&#x27;, ElasticNet())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                             ('elasticnet', ElasticNet())]),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'elasticnet__alpha': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
              "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
              "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37...\n",
              "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
              "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
              "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
              "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
              "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
              "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
              "       0.99]),\n",
              "                                        'elasticnet__max_iter': [10, 100, 1000,\n",
              "                                                                 10000]},\n",
              "                   random_state=42)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform hyperparameter tuning with RandomizedSearchCV\n",
        "random_search_lasso = RandomizedSearchCV(lasso_pipeline, rand_lasso_params, cv=5, n_jobs=-1, random_state=42)\n",
        "random_search_ridge = RandomizedSearchCV(ridge_pipeline, rand_ridge_params, cv=5, n_jobs=-1, random_state=42)\n",
        "random_search_elasticnet = RandomizedSearchCV(elasticnet_pipeline, rand_elasticnet_params, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_lasso.fit(X_trainval, y_trainval)\n",
        "random_search_ridge.fit(X_trainval, y_trainval)\n",
        "random_search_elasticnet.fit(X_trainval, y_trainval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qfsyfJsady_7"
      },
      "outputs": [],
      "source": [
        "# Get the best model and its parameters from GridSearchCV\n",
        "best_model_grid_linear = grid_search_linear.best_estimator_\n",
        "\n",
        "best_model_lasso = grid_search_lasso.best_estimator_\n",
        "best_params_lasso = grid_search_lasso.best_params_\n",
        "\n",
        "best_model_ridge = grid_search_ridge.best_estimator_\n",
        "best_params_ridge = grid_search_ridge.best_params_\n",
        "\n",
        "best_model_elasticnet = grid_search_elasticnet.best_estimator_\n",
        "best_params_elasticnet = grid_search_elasticnet.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JHvXukYDd2NE"
      },
      "outputs": [],
      "source": [
        "# Get the best model and its parameters from RandomizedSearchCV\n",
        "best_model_random_lasso = random_search_lasso.best_estimator_\n",
        "best_params_random_lasso = random_search_lasso.best_params_\n",
        "\n",
        "best_model_random_ridge = random_search_ridge.best_estimator_\n",
        "best_params_random_ridge = random_search_ridge.best_params_\n",
        "\n",
        "best_model_random_elasticnet = random_search_elasticnet.best_estimator_\n",
        "best_params_random_elasticnet = random_search_elasticnet.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ZYluLdbMTqAS",
        "outputId": "601700e6-551a-4ef8-c9a6-ad343496d73c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;elasticnet&#x27;, ElasticNet(alpha=1.37, l1_ratio=0.21))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;elasticnet&#x27;, ElasticNet(alpha=1.37, l1_ratio=0.21))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=1.37, l1_ratio=0.21)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('elasticnet', ElasticNet(alpha=1.37, l1_ratio=0.21))])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_random_elasticnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ptmMJbKVd3pt"
      },
      "outputs": [],
      "source": [
        "# Evaluate the models on the test set\n",
        "y_pred_linear = best_model_grid_linear.predict(X_test)\n",
        "\n",
        "y_pred_lasso = best_model_lasso.predict(X_test)\n",
        "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "\n",
        "y_pred_ridge = best_model_ridge.predict(X_test)\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "y_pred_elasticnet = best_model_elasticnet.predict(X_test)\n",
        "mse_elasticnet = mean_squared_error(y_test, y_pred_elasticnet)\n",
        "mae_elasticnet = mean_absolute_error(y_test, y_pred_elasticnet)\n",
        "r2_elasticnet = r2_score(y_test, y_pred_elasticnet)\n",
        "\n",
        "y_pred_random_lasso = best_model_random_lasso.predict(X_test)\n",
        "mse_random_lasso = mean_squared_error(y_test, y_pred_random_lasso)\n",
        "mae_random_lasso = mean_absolute_error(y_test, y_pred_random_lasso)\n",
        "r2_random_lasso = r2_score(y_test, y_pred_random_lasso)\n",
        "\n",
        "y_pred_random_ridge = best_model_random_ridge.predict(X_test)\n",
        "mse_random_ridge = mean_squared_error(y_test, y_pred_random_ridge)\n",
        "mae_random_ridge = mean_absolute_error(y_test, y_pred_random_ridge)\n",
        "r2_random_ridge = r2_score(y_test, y_pred_random_ridge)\n",
        "\n",
        "y_pred_random_elasticnet = best_model_random_elasticnet.predict(X_test)\n",
        "mse_random_elasticnet = mean_squared_error(y_test, y_pred_random_elasticnet)\n",
        "mae_random_elasticnet = mean_absolute_error(y_test, y_pred_random_elasticnet)\n",
        "r2_random_elasticnet = r2_score(y_test, y_pred_random_elasticnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vachA-sUd5BT",
        "outputId": "1477f14d-a32e-409f-f31b-62a0047451b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for best LinearRegression model:\n",
            "MSE: 0.5518\n",
            "MAE: 0.5314\n",
            "R^2: 0.5789\n",
            "\n",
            "Results for best Lasso model (GridSearchCV):\n",
            "MSE: 0.6790\n",
            "MAE: 0.6216\n",
            "R^2: 0.4818\n",
            "Best parameters: {'lasso__alpha': 0.1, 'lasso__max_iter': 100}\n",
            "\n",
            "Results for best Ridge model (GridSearchCV):\n",
            "MSE: 0.5518\n",
            "MAE: 0.5314\n",
            "R^2: 0.5789\n",
            "Best parameters: {'ridge__alpha': 0.1, 'ridge__max_iter': 100}\n",
            "\n",
            "Results for best ElasticNet model (GridSearchCV):\n",
            "MSE: 0.5824\n",
            "MAE: 0.5637\n",
            "R^2: 0.5556\n",
            "Best parameters: {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1, 'elasticnet__max_iter': 100}\n",
            "\n",
            "Results for best Lasso model (RandomizedSearchCV):\n",
            "MSE: 0.7429\n",
            "MAE: 0.6579\n",
            "R^2: 0.4331\n",
            "Best parameters: {'lasso__alpha': 0.2}\n",
            "\n",
            "Results for best Ridge model (RandomizedSearchCV):\n",
            "MSE: 0.5518\n",
            "MAE: 0.5314\n",
            "R^2: 0.5789\n",
            "Best parameters: {'ridge__max_iter': 10, 'ridge__alpha': 2.15}\n",
            "\n",
            "Results for best ElasticNet model (RandomizedSearchCV):\n",
            "MSE: 0.9501\n",
            "MAE: 0.7644\n",
            "R^2: 0.2750\n",
            "Best parameters: {'elasticnet__max_iter': 1000, 'elasticnet__l1_ratio': 0.21, 'elasticnet__alpha': 1.37}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "print(\"Results for best LinearRegression model:\")\n",
        "print(\"MSE: {:.4f}\".format(mean_squared_error(y_test, y_pred_linear)))\n",
        "print(\"MAE: {:.4f}\".format(mean_absolute_error(y_test, y_pred_linear)))\n",
        "print(\"R^2: {:.4f}\".format(r2_score(y_test, y_pred_linear)))\n",
        "print()\n",
        "\n",
        "print(\"Results for best Lasso model (GridSearchCV):\")\n",
        "print(\"MSE: {:.4f}\".format(mse_lasso))\n",
        "print(\"MAE: {:.4f}\".format(mae_lasso))\n",
        "print(\"R^2: {:.4f}\".format(r2_lasso))\n",
        "print(\"Best parameters: {}\".format(best_params_lasso))\n",
        "print()\n",
        "\n",
        "print(\"Results for best Ridge model (GridSearchCV):\")\n",
        "print(\"MSE: {:.4f}\".format(mse_ridge))\n",
        "print(\"MAE: {:.4f}\".format(mae_ridge))\n",
        "print(\"R^2: {:.4f}\".format(r2_ridge))\n",
        "print(\"Best parameters: {}\".format(best_params_ridge))\n",
        "print()\n",
        "\n",
        "print(\"Results for best ElasticNet model (GridSearchCV):\")\n",
        "print(\"MSE: {:.4f}\".format(mse_elasticnet))\n",
        "print(\"MAE: {:.4f}\".format(mae_elasticnet))\n",
        "print(\"R^2: {:.4f}\".format(r2_elasticnet))\n",
        "print(\"Best parameters: {}\".format(best_params_elasticnet))\n",
        "print()\n",
        "\n",
        "print(\"Results for best Lasso model (RandomizedSearchCV):\")\n",
        "print(\"MSE: {:.4f}\".format(mse_random_lasso))\n",
        "print(\"MAE: {:.4f}\".format(mae_random_lasso))\n",
        "print(\"R^2: {:.4f}\".format(r2_random_lasso))\n",
        "print(\"Best parameters: {}\".format(best_params_random_lasso))\n",
        "print()\n",
        "\n",
        "print(\"Results for best Ridge model (RandomizedSearchCV):\")\n",
        "print(\"MSE: {:.4f}\".format(mse_random_ridge))\n",
        "print(\"MAE: {:.4f}\".format(mae_random_ridge))\n",
        "print(\"R^2: {:.4f}\".format(r2_random_ridge))\n",
        "print(\"Best parameters: {}\".format(best_params_random_ridge))\n",
        "print()\n",
        "\n",
        "print(\"Results for best ElasticNet model (RandomizedSearchCV):\")\n",
        "print(\"MSE: {:.4f}\".format(mse_random_elasticnet))\n",
        "print(\"MAE: {:.4f}\".format(mae_random_elasticnet))\n",
        "print(\"R^2: {:.4f}\".format(r2_random_elasticnet))\n",
        "print(\"Best parameters: {}\".format(best_params_random_elasticnet))\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
