{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how one-hot encoding works\n",
    "\n",
    "Author: Umberto Michelucci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Iris dataset for this small test. Here is a brief description.\n",
    "\n",
    "## Iris Dataset Overview\n",
    "\n",
    "The Iris dataset is a classic and widely used dataset in the field of machine learning and statistics. It was introduced by the British statistician and biologist Ronald Fisher in 1936.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Data Points**: The dataset contains 150 data points, divided equally among three species of Iris flowers: Iris setosa, Iris versicolor, and Iris virginica.\n",
    "- **Features**: There are four features measured in centimeters for each sample:\n",
    "  - Sepal Length\n",
    "  - Sepal Width\n",
    "  - Petal Length\n",
    "  - Petal Width\n",
    "- **Target Variable**: The species of the Iris plant. The dataset includes three classes:\n",
    "  1. Iris setosa\n",
    "  2. Iris versicolor\n",
    "  3. Iris virginica\n",
    "\n",
    "### Usage\n",
    "\n",
    "The Iris dataset is often used in data science and machine learning, particularly for:\n",
    "- Demonstrating classification algorithms.\n",
    "- Teaching data visualization and exploratory data analysis.\n",
    "- Testing data preprocessing techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that the labels are not shuffled but sorted? Do you think this may be a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding the Labels\n",
    "\n",
    "### One-hot encoding Process\n",
    "\n",
    "One-hot encoding is a process used to convert categorical data into a numerical format that can be understood by machine learning algorithms. It is particularly useful for handling nominal data, where there is no inherent order in the categories. Here's a brief description of the process:\n",
    "\n",
    "### Steps in One-Hot Encoding\n",
    "1. **Identify Categorical Data**:\n",
    "   - The first step is to identify which features in your dataset are categorical. These could be in string format or represented as discrete values.\n",
    "\n",
    "2. **List Unique Categories**:\n",
    "   - For each categorical feature, list all the unique categories it contains.\n",
    "\n",
    "3. **Create Binary Features**:\n",
    "   - For each unique category, create a new binary feature (column) in your dataset.\n",
    "   - The number of binary features created for each categorical feature will be equal to the number of unique categories in that feature.\n",
    "\n",
    "4. **Assign Binary Values**:\n",
    "   - For each record, assign a value of 1 in the binary feature that corresponds to the category present in the original feature and 0 in all other binary features created for that category.\n",
    "   - Essentially, only one of these binary features will have a 1 for each record, and the rest will have 0s.\n",
    "\n",
    "### Example\n",
    "Consider a categorical feature \"Color\" with three categories: Red, Blue, and Green. One-hot encoding will create three new features: \"Color_Red\", \"Color_Blue\", and \"Color_Green\". For a record with the color Red, the values for these features will be:\n",
    "\n",
    "- Color_Red: 1\n",
    "- Color_Blue: 0\n",
    "- Color_Green: 0\n",
    "\n",
    "### Why Use One-Hot Encoding?\n",
    "- **Machine Learning Compatibility**: Many machine learning models, especially those based on mathematical algorithms, require numerical input. One-hot encoding converts categorical data into a numerical format these models can work with.\n",
    "- **Removing Ordinality**: It helps to remove any ordinal relationship that might be wrongly interpreted by the algorithm (important for nominal categories).\n",
    "\n",
    "### Considerations\n",
    "- **Dimensionality Increase**: One-hot encoding can significantly increase the number of features in your dataset, especially if the categorical variables have many unique categories (known as the \"curse of dimensionality\").\n",
    "- **Dummy Variable Trap**: It can lead to multicollinearity due to the addition of multiple binary features. To avoid this, sometimes one category is dropped (reducing the number of binary features by one).\n",
    "\n",
    "\n",
    "### ```OneHotEncoder()``` Function\n",
    "\n",
    "`OneHotEncoder()` is a function from scikit-learn, a popular Python library for machine learning. It is used for preprocessing categorical data. This function encodes categorical variables as a one-hot numeric array, which is a common requirement for many machine learning algorithms to work effectively. Here's a detailed description:\n",
    "\n",
    "### Overview of `OneHotEncoder()`\n",
    "1. **Purpose**:\n",
    "   - The primary purpose of `OneHotEncoder()` is to convert categorical data into a format that can be more easily processed by machine learning algorithms. It creates a binary column for each category and returns a sparse matrix or dense array.\n",
    "\n",
    "2. **Functionality**:\n",
    "   - For each unique category in a feature, `OneHotEncoder()` creates a new binary feature that indicates whether the category is present in each row.\n",
    "\n",
    "### Key Features and Parameters\n",
    "1. **Parameters**:\n",
    "   - `categories`: Specifies the categories to be encoded. By default, categories are automatically determined from the training data.\n",
    "   - `drop`: Whether to drop one of the categories to avoid creating collinear features.\n",
    "   - `sparse`: If set to `True`, the encoder returns a sparse matrix; if `False`, a dense array is returned.\n",
    "   - `handle_unknown`: Specifies how to handle categories not seen during training (can be set to 'error' or 'ignore').\n",
    "\n",
    "2. **Methods**:\n",
    "   - `fit(X[, y])`: Fit the OneHotEncoder to X.\n",
    "   - `transform(X)`: Transform X using the one-hot encoding.\n",
    "   - `fit_transform(X[, y])`: Fit to data, then transform it.\n",
    "\n",
    "3. **Output**:\n",
    "   - After transformation, each unique category value of the feature is converted into a binary column, with `1` indicating the presence of the category and `0` indicating the absence.\n",
    "\n",
    "### Example Usage\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = np.array([['red'], ['green'], ['blue']])\n",
    "\n",
    "# Create the encoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform data\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "print(encoded_data)\n",
    "```\n",
    "\n",
    "### Considerations\n",
    "- **Dummy Variable Trap**: One-hot encoding creates multiple binary columns for each category, which can lead to multicollinearity. Sometimes, one of the binary columns is dropped to avoid this issue.\n",
    "- **Handling Unknown Categories**: The parameter `handle_unknown` can be used to handle categories that were not seen during training.\n",
    "- **Memory Usage**: For a large number of categories, one-hot encoding can significantly increase the dataset's size. The `sparse=True` option can be used to mitigate memory usage issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umberto/miniforge3/envs/tf2/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# The y array currently contains integers representing the classes.\n",
    "# We will now convert these class labels into one-hot encoded format.\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)  # sparse=False to get a dense matrix\n",
    "\n",
    "# Reshape y to 2D array as fit_transform expects 2D array\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Apply the encoder on the reshaped y\n",
    "y_one_hot = encoder.fit_transform(y)\n",
    "\n",
    "# y_one_hot now contains the one-hot encoded labels\n",
    "print(y_one_hot[0:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
